from pathlib import Path
import sys
from envs.registration import make
import agents
import wrappers
import json
import os
import argparse
import logging
import time
from typing import Dict, List, Tuple, Optional
from LearnArena.learnarena_utils.utils import (
    create_agent,
    get_game_summary,
    score_game_quality,
    generate_instructor_feedback,
    generate_experience_analysis,
    start_vllm_server,
    stop_vllm_server
)
import re

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename=f'logs/learnarena_benchmark_{time.strftime("%Y%m%d_%H%M%S")}.log'
)
logger = logging.getLogger(__name__)

class LearnArenaBenchmark:
    """
    LearnArena: A benchmark suite for evaluating general learning ability across three dimensions:
    1. Learning from Instructor: Player-0 provides suggestions for improvement
    2. Learning from Concept: Concise game rule summaries generated by Qwen2.5-32B
    3. Learning from Experience: Player-1 analyzes past experiences and applies conclusions
    """
    
    def __init__(self, player0_model: str = "qwen2.5-32b-chat", player0_port: int = 8000, 
                 player1_port: int = 8001, mode: str = "vllm",
                 player0_api_base: str = None, player0_api_key: str = None,
                 player1_api_base: str = None, player1_api_key: str = None):
        self.player0_model = player0_model
        self.player0_port = player0_port
        self.player1_port = player1_port
        self.game_summaries = {}  # Cache for game summaries
        self.mode = mode
        self.player0_api_base = player0_api_base
        self.player0_api_key = player0_api_key
        self.player1_api_base = player1_api_base
        self.player1_api_key = player1_api_key
        
    def get_agent(self, model_name: str, port: int, is_player0: bool = True):
        """Create an agent with specified model and port"""
        api_base = self.player0_api_base if is_player0 else self.player1_api_base
        api_key = self.player0_api_key if is_player0 else self.player1_api_key
        
        return create_agent(
            model_name=model_name,
            port=port,
            mode=self.mode,
            api_base=api_base,
            api_key=api_key,
            is_player0=is_player0,
            timeout=120
        )
    
    def get_game_summary(self, game: str, agent, env) -> str:
        """Generate or load a summary of the game rules with strategic advice for winning"""
        return get_game_summary(game, agent, env)
    
    def select_top_experiences(self, game_experiences: List[Dict], k: int = 3) -> List[Dict]:
        """
        Select top k experiences from previous games based on game quality scores.
        Player-1 selects three experiences from the previous k-1 games.
        """
        if len(game_experiences) < k:
            return game_experiences
        
        # Sort by score (higher is better) and return top k
        sorted_experiences = sorted(game_experiences, key=lambda x: x.get('score', 0), reverse=True)
        return sorted_experiences[:k]
    
    def generate_instructor_feedback(self, player0_agent, game_history: Dict, game_outcome: str) -> str:
        """
        Learning from Instructor: Player-0 provides suggestions for improvement.
        """
        return generate_instructor_feedback(player0_agent, game_history, game_outcome)    
    def generate_experience_analysis(self, player1_agent, selected_experiences: List[Dict]) -> str:
        """
        Learning from Experience: Player-1 analyzes selected past experiences and draws conclusions.
        """
        return generate_experience_analysis(player1_agent, selected_experiences)
    
    def combine_instructor_feedback(self, player0_agent, selected_experiences: List[Dict]) -> str:
        """
        Combine instructor feedback from top selected experiences into a coherent strategic guide.
        """
        if not selected_experiences:
            return ""
        
        # Save original system prompt
        original_prompt = player0_agent.system_prompt
        
        try:
            # Set system prompt for combining feedback
            player0_agent.system_prompt = ("You are an expert game instructor. "
                                           "Your task is to provide detailed strategic "
                                           "advice for the game based on the provided information.")
            
            # Create prompt for combining feedback
            combine_prompt = "Analyze this history and provide strategic advice.\n\n"
            combine_prompt += "Game history: "
            
            for i, exp in enumerate(selected_experiences, 1):
                outcome = exp.get('outcome', 'Unknown')
                score = exp.get('score', 0)
                combine_prompt += f"Experience #{i} (Score: {score}/10, Outcome: {outcome}):\n"
                
                if 'moves' in exp and exp['moves']:
                    last_move = exp['moves'][-1]
                    combine_prompt += f"Last move: {last_move.get('action', 'N/A')}\n"
                    combine_prompt += f"Last observation: {last_move.get('observation', 'N/A')}\n"
                
                combine_prompt += "\n"

            
            combine_prompt += ("Provide your analysis in this format:\n"
                              "1. Strategic principles to follow\n"
                              "2. Specific moves to consider\n"
                              "3. Moves to avoid\n"
                              "4. Key patterns to watch for\n\n")
            
            # Get combined feedback
            combined_feedback = player0_agent(combine_prompt)
            if combined_feedback is None or "Error:" in combined_feedback:
                logger.error(f"Error combining instructor feedback: {combined_feedback}")
                return ""
            
            return combined_feedback
            
        except Exception as e:
            logger.error(f"Exception combining instructor feedback: {type(e).__name__}: {str(e)}")
            return ""
        finally:
            # Restore original system prompt
            player0_agent.system_prompt = original_prompt
    
    def score_game_quality(self, player0_agent, game_history: Dict, game_outcome: str) -> int:
        """Score the game quality on a scale of 0-10 using Player-0 as judge"""
        return score_game_quality(player0_agent, game_history, game_outcome)
    
    def run_single_game(self, game: str, player1_model: str, game_round: int, 
                       game_experiences: List[Dict], learning_enabled: bool = True) -> Dict:
        """
        Run a single game between Player-0 (Qwen2.5-32B) and Player-1 (evaluated model).
        
        Args:
            game: Game environment ID
            player1_model: Model name for Player-1
            game_round: Current round number
            game_experiences: Previous game experiences for learning
            learning_enabled: Whether to apply learning from previous experiences
        """
        logger.info(f"Starting game round {game_round} for {game} with Player-1: {player1_model}")
        
        # Initialize agents
        player0_agent = self.get_agent(self.player0_model, self.player0_port, is_player0=True)
        player1_agent = self.get_agent(player1_model, self.player1_port, is_player0=False)
        
        # Initialize environment
        env = make(env_id=game)
        env = wrappers.LLMObservationWrapper(env=env)
        env = wrappers.SimpleRenderWrapper(
            env=env,
            player_names={0: "Player0", 1: "Player1"},
        )
        
        # Get game summary (Learning from Concept)
        if game not in self.game_summaries:
            self.game_summaries[game] = self.get_game_summary(game, player0_agent, env)
        
        game_summary = self.game_summaries[game]
        
        # Apply learning if enabled and we have previous experiences
        if learning_enabled and game_round > 1 and game_experiences:
            logger.info(f"Applying learning from {len(game_experiences)} previous experiences")
            
            # Learning from Experience: Select top experiences
            selected_experiences = self.select_top_experiences(game_experiences)
            experience_analysis = self.generate_experience_analysis(player1_agent, selected_experiences)
            
            # Learning from Instructor: Get instructor feedback from selected experiences
            instructor_feedback = self.combine_instructor_feedback(player0_agent, selected_experiences)
            
            # Combine all learning sources in Player-1's system prompt
            original_prompt = player1_agent.system_prompt
            
            learning_prompt = ""
            
            # Add Learning from Concept
            if game_summary and not "Error" in game_summary:
                learning_prompt += f"GAME ANALYSIS AND WINNING STRATEGIES:\n{game_summary}\n\n"
            
            # Add Learning from Instructor
            if instructor_feedback:
                learning_prompt += f"INSTRUCTOR FEEDBACK:\n{instructor_feedback}\n\n"
            
            # Add Learning from Experience
            if experience_analysis:
                learning_prompt += f"EXPERIENCE ANALYSIS:\n{experience_analysis}\n\n"
            
            if learning_prompt:
                learning_prompt += "REMEMBER: Apply these strategic principles and insights consistently to maximize your chances of winning.\n\n"
                player1_agent.system_prompt = learning_prompt + original_prompt
            
            # Track selected experiences for debugging
            selected_experience_info = [
                {
                    "round": exp.get("round", "Unknown"),
                    "outcome": exp.get("outcome", "Unknown"),
                    "score": exp.get("score", 0)
                }
                for exp in selected_experiences
            ]
        else:
            # For first game or when learning is disabled, only add game summary
            selected_experience_info = []
            if game_summary and not "Error" in game_summary:
                original_prompt = player1_agent.system_prompt
                concept_prompt = f"GAME ANALYSIS AND WINNING STRATEGIES:\n{game_summary}\n\nREMEMBER: Apply these strategic principles consistently to maximize your chances of winning.\n\n"
                player1_agent.system_prompt = concept_prompt + original_prompt
        
        # Play the game
        agents = {0: player0_agent, 1: player1_agent}
        
        env.reset(num_players=len(agents))
        game_history = {
            "moves": [],
            "outcome": None
        }
        
        done = False
        move_count = 0
        
        try:
            while not done:
                player_id, observation = env.get_observation()
                logger.debug(f"Player {player_id}'s turn - Move {move_count + 1}")
                
                action = agents[player_id](observation)
                logger.debug(f"Player {player_id} action: {action}")
                
                done, info = env.step(action=action)
                
                game_history["moves"].append({
                    "player": player_id,
                    "observation": observation,
                    "action": action
                })
                move_count += 1
            
            rewards = env.close()
            logger.info(f"Game {game_round} completed. Rewards: Player0={rewards[0]}, Player1={rewards[1]}")
            
            # Determine game outcome
            if rewards[0] > rewards[1]:
                game_history["outcome"] = "Player 0 won"
                player1_won = False
            elif rewards[1] > rewards[0]:
                game_history["outcome"] = "Player 1 won"
                player1_won = True
            else:
                game_history["outcome"] = "Draw"
                player1_won = False
            
            # Generate instructor feedback (Learning from Instructor)
            instructor_feedback = self.generate_instructor_feedback(
                player0_agent, game_history, game_history["outcome"]
            )
            
            # Score the game quality
            game_score = self.score_game_quality(player0_agent, game_history, game_history["outcome"])
            
            result = {
                "game": game,
                "round": game_round,
                "player0_model": self.player0_model,
                "player1_model": player1_model,
                "learning_enabled": learning_enabled,
                "rewards": rewards,
                "outcome": game_history["outcome"],
                "player1_won": player1_won,
                "moves": game_history["moves"],
                "instructor_feedback": instructor_feedback,
                "score": game_score,
                "game_summary": game_summary,
                "error": None,
                "selected_experience_info": selected_experience_info
            }
            
            logger.info(f"Game {game_round} outcome: {game_history['outcome']}, Score: {game_score}/10")
            return result
            
        except Exception as e:
            logger.error(f"Error during game {game_round}: {str(e)}")
            return {
                "game": game,
                "round": game_round,
                "player0_model": self.player0_model,
                "player1_model": player1_model,
                "learning_enabled": learning_enabled,
                "rewards": [0, 0],
                "outcome": "Error",
                "player1_won": False,
                "moves": game_history["moves"],
                "instructor_feedback": None,
                "score": 0,
                "game_summary": game_summary,
                "error": str(e),
                "selected_experience_info": []
            }
    
    def run_benchmark(self, games: List[str], player1_model: str, output_file: str, 
                     num_rounds: int = 20, learning_enabled: bool = True) -> List[Dict]:
        """
        Run the complete LearnArena benchmark for a given model.
        
        Args:
            games: List of game environment IDs
            player1_model: Model name for Player-1
            output_file: Path to save results
            num_rounds: Number of rounds per game
            learning_enabled: Whether to enable learning across rounds
        """
        logger.info(f"Starting LearnArena benchmark for {player1_model}")
        logger.info(f"Games: {games}")
        logger.info(f"Rounds per game: {num_rounds}")
        logger.info(f"Learning enabled: {learning_enabled}")
        
        all_results = []
        
        for game in games:
            logger.info(f"Starting benchmark for game: {game}")
            game_experiences = []  # Store experiences for this game
            game_results = []
            
            for round_num in range(1, num_rounds + 1):
                # Run single game
                result = self.run_single_game(
                    game=game,
                    player1_model=player1_model,
                    game_round=round_num,
                    game_experiences=game_experiences,
                    learning_enabled=learning_enabled
                )
                
                game_results.append(result)
                all_results.append(result)
                
                # Add to experiences for learning (exclude current round from future learning)
                if result["error"] is None:
                    experience = {
                        "round": round_num,
                        "outcome": result["outcome"],
                        "score": result["score"],
                        "moves": result["moves"],
                        "instructor_feedback": result["instructor_feedback"]
                    }
                    game_experiences.append(experience)
                
                # Save results after each game
                with open(output_file, 'w') as f:
                    json.dump(all_results, f, indent=2)
                
                logger.info(f"Completed round {round_num}/{num_rounds} for {game}")
            
            # Calculate game statistics
            wins = sum(1 for r in game_results if r["player1_won"])
            win_rate = wins / num_rounds if num_rounds > 0 else 0
            avg_score = sum(r["score"] for r in game_results) / num_rounds if num_rounds > 0 else 0
            
            logger.info(f"Game {game} completed:")
            logger.info(f"  Win rate: {win_rate:.2%} ({wins}/{num_rounds})")
            logger.info(f"  Average score: {avg_score:.1f}/10")
        
        logger.info("LearnArena benchmark completed")
        return all_results

def parse_games_input(games_str: str) -> List[str]:
    """Parse comma-separated games string into a list of games"""
    if not games_str:
        raise ValueError("Games input cannot be empty")
    
    games = [game.strip() for game in games_str.split(',')]
    games = [game for game in games if game]
    
    if not games:
        raise ValueError("No valid games found in input")
        
    return games

def main():
    parser = argparse.ArgumentParser(description="LearnArena: Benchmark for General Learning Ability")
    parser.add_argument("--player0-model", type=str, default="qwen2.5-32b-chat", help="Model name for Player-0 (instructor)")
    parser.add_argument("--player0-path", type=str, required=False, help="Path to Player-0 model (for vLLM mode)")
    parser.add_argument("--player1-model", type=str, required=True, help="Model name for Player-1 (evaluated model)")
    parser.add_argument("--player1-path", type=str, required=False, help="Path to Player-1 model (for vLLM mode)")
    parser.add_argument("--games", type=str, required=True, help="Comma-separated list of games to evaluate")
    parser.add_argument("--output-file", type=str, required=True, help="Output JSON file path")
    parser.add_argument("--num-rounds", type=int, default=20, help="Number of rounds per game")
    parser.add_argument("--gpu", type=int, default=4, help="Number of GPUs to use (vLLM mode)")
    
    # API mode arguments
    parser.add_argument("--mode", type=str, default="vllm", choices=["vllm", "api"], 
                       help="Mode: 'vllm' for local vLLM servers, 'api' for external API endpoints")
    parser.add_argument("--player0-api-base", type=str, help="API base URL for Player-0 (API mode)")
    parser.add_argument("--player0-api-key", type=str, help="API key for Player-0 (API mode, or set API_KEY_0 env var)")
    parser.add_argument("--player1-api-base", type=str, help="API base URL for Player-1 (API mode)")
    parser.add_argument("--player1-api-key", type=str, help="API key for Player-1 (API mode, or set API_KEY_1 env var)")
    args = parser.parse_args()
    
    # Validate arguments based on mode
    if args.mode == "vllm":
        if not args.player0_path or not args.player1_path:
            parser.error("--player0-path and --player1-path are required for vLLM mode")
    elif args.mode == "api":
        if not args.player0_api_base or not args.player1_api_base:
            parser.error("--player0-api-base and --player1-api-base are required for API mode")
    
    # Parse games
    try:
        games = parse_games_input(args.games)
        logger.info(f"Parsed games: {games}")
    except ValueError as e:
        logger.error(f"Error parsing games input: {str(e)}")
        sys.exit(1)
    
    # Create output directory
    output_dir = os.path.dirname(args.output_file)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    server_processes = []
    
    if args.mode == "vllm":
        # Start vLLM servers
        # Start Player-0 server (Qwen2.5-32B instructor)
        logger.info(f"Starting vLLM server for Player-0 ({args.player0_model}) at {args.player0_path}...")
        proc0 = start_vllm_server(
            model_path=args.player0_path,
            model_name=args.player0_model,
            port=8000,
            gpu=args.gpu
        )
        server_processes.append(proc0)
        
        # Start Player-1 server (evaluated model)
        logger.info(f"Starting vLLM server for Player-1 ({args.player1_model}) at {args.player1_path}...")
        proc1 = start_vllm_server(
            model_path=args.player1_path,
            model_name=args.player1_model,
            port=8001,
            gpu=args.gpu
        )
        server_processes.append(proc1)
    else:
        logger.info(f"Using API mode with Player-0: {args.player0_api_base}, Player-1: {args.player1_api_base}")
    
    try:
        # Initialize benchmark
        benchmark = LearnArenaBenchmark(
            player0_model=args.player0_model,
            player0_port=8000,
            player1_port=8001,
            mode=args.mode,
            player0_api_base=args.player0_api_base,
            player0_api_key=args.player0_api_key,
            player1_api_base=args.player1_api_base,
            player1_api_key=args.player1_api_key
        )
        
        # Run benchmark
        results = benchmark.run_benchmark(
            games=games,
            player1_model=args.player1_model,
            output_file=args.output_file,
            num_rounds=args.num_rounds,
            learning_enabled=True
        )
        
        # Print summary
        print("\nLearnArena Benchmark Results Summary:")
        print("=" * 80)
        
        # Group results by game
        games_results = {}
        for result in results:
            game = result['game']
            if game not in games_results:
                games_results[game] = []
            games_results[game].append(result)
        
        total_wins = 0
        total_games = 0
        total_score = 0
        
        for game, game_results in games_results.items():
            wins = sum(1 for r in game_results if r["player1_won"])
            win_rate = wins / len(game_results) if game_results else 0
            avg_score = sum(r["score"] for r in game_results) / len(game_results) if game_results else 0
            
            print(f"\nGame: {game}")
            print(f"Player-0 Model: {args.player0_model}")
            print(f"Player-1 Model: {args.player1_model}")
            print(f"Win Rate: {win_rate:.2%} ({wins}/{len(game_results)})")
            print(f"Average Score: {avg_score:.1f}/10")
            print("-" * 40)
            
            total_wins += wins
            total_games += len(game_results)
            total_score += avg_score * len(game_results)
        
        # Overall statistics
        overall_win_rate = total_wins / total_games if total_games > 0 else 0
        overall_avg_score = total_score / total_games if total_games > 0 else 0
        
        print(f"\nOVERALL PERFORMANCE:")
        print(f"Total Win Rate: {overall_win_rate:.2%} ({total_wins}/{total_games})")
        print(f"Overall Average Score: {overall_avg_score:.1f}/10")
        print(f"Results saved to: {args.output_file}")
        
    finally:
        # Stop all vLLM servers
        if args.mode == "vllm":
            for proc in server_processes:
                stop_vllm_server(proc)

if __name__ == "__main__":
    main() 